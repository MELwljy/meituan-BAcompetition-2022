{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7071c8b8",
   "metadata": {},
   "source": [
    "## 1:Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d1a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport  \n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV,Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split,RepeatedKFold,GridSearchCV\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import math\n",
    "from functions import *\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b24d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define any blank value as NA \n",
    "missing_values_char = ['']\n",
    "df = pd.read_excel('数据/dataset_version5_Final.xlsx',na_values=missing_values_char)\n",
    "dfclean = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa5c184",
   "metadata": {},
   "source": [
    "## 2: Data Clean and pre-process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374caa3",
   "metadata": {},
   "source": [
    "###### 2-1 delivery_type_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a876d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip the column for delivery_type_1\n",
    "dfclean.delivery_type_1 = dfclean.delivery_type_1.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde53656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace value with ENG\n",
    "dfclean['delivery_type_1'] = dfclean['delivery_type_1'].replace(['美团快送'],'MeituanFlash')\n",
    "dfclean['delivery_type_1'] = dfclean['delivery_type_1'].replace(['美团跑腿'],'MeituanRun')\n",
    "dfclean['delivery_type_1'] = dfclean['delivery_type_1'].replace(['商家'],'Merchant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4198a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop delivery_type NA value\n",
    "dfclean = dfclean.dropna(subset=['delivery_type_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b14612",
   "metadata": {},
   "source": [
    "###### 2-2 category1\n",
    "```\n",
    "Did not slice the category1 feature into subgroups. Try to keep the integrity of the data set \n",
    "as much as possible\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2d3603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip the column for category1\n",
    "dfclean.category1 = dfclean.category1.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e7ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace value with ENG\n",
    "dfclean['category1'] = dfclean['category1'].replace(['超市便利'],'MarketConvenience')\n",
    "dfclean['category1'] = dfclean['category1'].replace(['浪漫鲜花'],'RomanticFlowers')\n",
    "dfclean['category1'] = dfclean['category1'].replace(['美食'],'Foods')\n",
    "dfclean['category1'] = dfclean['category1'].replace(['生鲜果蔬'],'FruitVegetables')\n",
    "dfclean['category1'] = dfclean['category1'].replace(['送药上门'],'DrugsDeliveried')\n",
    "dfclean['category1'] = dfclean['category1'].replace(['甜点饮品'],'DessertDrink')\n",
    "dfclean['category1'] = dfclean['category1'].replace(['甜蜜蛋糕'],'SweetCake')\n",
    "dfclean['category1'] = dfclean['category1'].replace(['未知'],'Unkown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d95e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop category1 \"未知\" value\n",
    "dfclean = dfclean[dfclean.category1!='Unkown']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59af6d94",
   "metadata": {},
   "source": [
    "###### 2-3 in_time_delivery_percent\n",
    "```\n",
    "13% of in_time_delivery_percent values are zero. Yet, I investigate the features distributions under in_time_delivery_percent==0.\n",
    "Most of the distributions actually make sense. in_time_delivery_percent == 0 just means it takes a long time to deliver. So these many zero valeus actually means something, decide not to drop them\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7266bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 800s NA value in_time_delivery_percent feature, since this feature is curical in the upcoming data minning\n",
    "# Drop all NA value in this feature\n",
    "dfclean = dfclean.dropna(subset=['in_time_delivery_percent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946d6155",
   "metadata": {},
   "source": [
    "###### 2-4 delivery_tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386bf5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the delivery tip feature, since we already have delivery_type_1 \n",
    "dfclean.drop(columns=['delivery_tip'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e78a18",
   "metadata": {},
   "source": [
    "###### 2-5 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c9d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop score equal to zero \n",
    "# score is the output variable candidate, 0 will affact the model significantly\n",
    "dfclean = dfclean[dfclean.score>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25988ef",
   "metadata": {},
   "source": [
    "###### 2-6 month_sales_clean\n",
    "```\n",
    "Not sure how to deal with the extrem value, may log the whole feature\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e59acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop month_sales_clean equal to zero \n",
    "# month_sales_clean is the output variable candidate, 0 will affact the model significantly\n",
    "dfclean = dfclean[dfclean.month_sales_clean>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746c0696",
   "metadata": {},
   "source": [
    "###### 2-7 min_price_rmb\n",
    "```\n",
    "15% of min_price_rmb values are zero. Yet, I investigate the features distributions under min_price_rmb==0.\n",
    "Most of the distributions actually make sense. min_price_rmb == 0 just means no barrier to make an order. So these many zero valeus actually means something, decide not to drop them\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5d5de",
   "metadata": {},
   "source": [
    "###### 2-8 comment_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf2a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only 0.1% of the values in comment_number are zero, we will drop them\n",
    "dfclean = dfclean[dfclean.comment_number>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047f56db",
   "metadata": {},
   "source": [
    "###### 2-9 delivery_time_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533de16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the delivery_time_clean <= 300 mins\n",
    "dfclean = dfclean[dfclean.delivery_time_clean<=300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dd5fc2",
   "metadata": {},
   "source": [
    "##### 2-10delivery_type_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c8528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary variable for delivery_type\n",
    "# Merchant = 1 else 0\n",
    "dfclean[['MeituanFlash','MeituanRun','Merchant']] = pd.get_dummies(dfclean['delivery_type_1'])\n",
    "dfclean['delivery_type_bin'] = dfclean['Merchant']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b20c9f",
   "metadata": {},
   "source": [
    "##### 2-11 month_sales_clean_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the log transformation for the month_sales_clean\n",
    "dfclean['month_sales_clean_log'] = np.log(dfclean.month_sales_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bdcc57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visulize and compared the log and non-log version\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(4, 3), dpi=100)\n",
    "plt.tight_layout()\n",
    "\n",
    "axs[0].hist(dfclean.month_sales_clean, bins=100)\n",
    "axs[1].hist(dfclean.month_sales_clean_log, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c619afb0",
   "metadata": {},
   "source": [
    "##### 2-12 Create subset by limiting category (foods & dessertdrink &sweetcake）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe4c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dffood=dfclean.drop(dfclean[dfclean['category1']=='MarketConvenience'].index)\n",
    "dffood=dffood.drop(dffood[dffood['category1']=='FruitVegetables'].index)\n",
    "dffood=dffood.drop(dffood[dffood['category1']=='RomanticFlowers'].index)\n",
    "dffood=dffood.drop(dffood[dffood['category1']=='DrugsDeliveried'].index)\n",
    "dffood['category1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ebeba",
   "metadata": {},
   "source": [
    "##### 2-13 category1 dummy (one hot encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7528173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfclean[['DessertDrink','DrugsDeliveried','Foods','FruitVegetables','MarketConvenience','RomanticFlowers','SweetCake']] = pd.get_dummies(dfclean['category1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d84014",
   "metadata": {},
   "source": [
    "##### 2-14 Exclude Education & Beauty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54936a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# education and beauty are sparse features which have tons of zero value. They won't add too much information in the model\n",
    "# so we will drop these two features\n",
    "dfclean.drop(columns=['Education'],inplace=True)\n",
    "dfclean.drop(columns=['Beauty'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e143d789",
   "metadata": {},
   "source": [
    "##### 2-14 Export Data-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb0200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfclean.to_excel('datasetv7_allcategory.xlsx',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6ddaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dffood.to_excel('datasetv8_food_drink_cake.xlsx',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb232f",
   "metadata": {},
   "source": [
    "## 3 EDA \n",
    "```\n",
    "Use these codes to do a sanitiy check for the cleanning\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd898fbb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "profile = ProfileReport(dffood, title=\"Pandas Profiling Report\")\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a2dd50",
   "metadata": {},
   "source": [
    "## 4: Visualization  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02640fe",
   "metadata": {},
   "source": [
    "```\n",
    "Refer to the correlation plot in the Auto EDA result, visualize features pairs of following\n",
    "in_time_delivery_percent -- delivery_time_clean \n",
    "delivery_time_clean      --- min_price_rmb\n",
    "comment_number           --- month_sales_clean_log \n",
    "day_time                 --- mid_night_time\n",
    "catergory1               --- avg_price_rmb\n",
    "delivery_type_1          --- avg_price_rmb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5821a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.dpi\":80, 'savefig.dpi':80})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a766d",
   "metadata": {},
   "source": [
    "###### 4-1 in_time_delivery_percent -- delivery_time_clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9869c829",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('dark')\n",
    "axes = sns.jointplot(\n",
    "    data=dfclean,\n",
    "    x=\"in_time_delivery_percent\",\n",
    "    y=\"delivery_time_clean\",\n",
    "    hue=\"delivery_type_bin\",\n",
    "    hue_order=[1, 0],\n",
    "    color=\"navy\",\n",
    "    palette=\"bright\",\n",
    "    #kind='hist'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f14238f",
   "metadata": {},
   "source": [
    "##### 4-2 delivery_time_clean      --- min_price_rmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9439ba4e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('dark')\n",
    "axes = sns.jointplot(\n",
    "    data=dfclean,\n",
    "    x=\"delivery_time_clean\",\n",
    "    y=\"min_price_rmb\",\n",
    "    hue=\"delivery_type_bin\",\n",
    "    hue_order=[1, 0],\n",
    "    color=\"navy\",\n",
    "    palette=\"bright\",\n",
    "    #kind='hist'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e326ee13",
   "metadata": {},
   "source": [
    "##### 4-3 comment_number           --- month_sales_clean_log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8781d6a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('dark')\n",
    "axes = sns.jointplot(\n",
    "    data=dfclean,\n",
    "    x=\"comment_number\",\n",
    "    y=\"month_sales_clean_log\",\n",
    "    hue=\"delivery_type_bin\",\n",
    "    hue_order=[1, 0],\n",
    "    color=\"navy\",\n",
    "    palette=\"bright\",\n",
    "    #kind='hist'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e172d6",
   "metadata": {},
   "source": [
    "##### 4-4 catergory1               --- avg_price_rmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a45a5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.dpi\":80, 'savefig.dpi':80})\n",
    "sns.set(rc={'figure.figsize':(12,4)})\n",
    "sns.set_style('dark')\n",
    "sns.boxplot(data=dfclean, x='category1',y='avg_price_rmb',palette='bright')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d09082",
   "metadata": {},
   "source": [
    "##### 4-5 delivery_type_1          --- avg_price_rmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2efcb20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.dpi\":60, 'savefig.dpi':60})\n",
    "sns.set(rc={'figure.figsize':(12,7)})\n",
    "sns.set_style('dark')\n",
    "sns.boxplot(data=dfclean, x='delivery_type_1',y='avg_price_rmb',palette='bright')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e3aafa",
   "metadata": {},
   "source": [
    "## 5: Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad17eb3b",
   "metadata": {},
   "source": [
    "### 5-1 Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598f8e5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,8))\n",
    "corrMatrix = dffood.corr()\n",
    "sns.heatmap(corrMatrix, annot=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec0ac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dffood.month_sales_clean.hist() # right skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8eb2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dffood.month_sales_clean_log.hist() # looks normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a314f8",
   "metadata": {},
   "source": [
    "### 5-2 Linear Regression\n",
    "The distribution of Y has a normal distribution with mean  μ and constant variance σ^2.  \n",
    "Link function - the identity link, η=g(E(Y))=E(Y), is used; this is the simplest link function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8302b435",
   "metadata": {},
   "source": [
    "#### 5-2-1 level-level regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dfdcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = ols('month_sales_clean ~ score+comment_number+avg_price_rmb+delivery_time_clean+delivery_type_1+in_time_delivery_percent+min_price_rmb+shipping_fee_clean+Day_Time+Night_Time+Mid_Night_Time+recommend_Bin', data=dffood).fit()\n",
    "print(results1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4bf8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE1=(np.square(results1.resid)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876474f9",
   "metadata": {},
   "source": [
    "We can write our simple linear regression model as\n",
    "\n",
    "$$\n",
    "{MonthlySales}_i = \\beta_0 + \\beta_1 {DeliveryType[T.MeituanRun]}_i + \\beta_2 {DeliveryType_1[T.Merchant]}_i+ \\beta_3 {Score}_i+ \\beta_4 {CommentNumber}_i+\\beta_5 {AvgPrice}_i+\\beta_6 {DeliveryTime}_i+\\beta_7 {InTimeDeliveryPercent}_i+\\beta_8 {MinPrice}_i+\\beta_9 {ShippingFee}_i+\\beta_{10} {DayTime}_i+\\beta_{11} {NightTime}_i+\\beta_{12} {MidNightTime}_i+\\beta_{13} {Recommendation}+u_i\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893f3dca",
   "metadata": {},
   "source": [
    "#### 5-2-2 Log-linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c7565",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = ols('month_sales_clean_log ~ score+comment_number+avg_price_rmb+delivery_time_clean+delivery_type_1+in_time_delivery_percent+min_price_rmb+shipping_fee_clean+Day_Time+Night_Time+Mid_Night_Time+recommend_Bin', data=dffood).fit()\n",
    "#print(results2.summary())\n",
    "\n",
    "results3 = ols('month_sales_clean_log ~ score+comment_number+avg_price_rmb+delivery_time_clean+delivery_type_1+in_time_delivery_percent+min_price_rmb+shipping_fee_clean+Day_Time+Mid_Night_Time+recommend_Bin', data=dffood).fit()\n",
    "#print(results3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd4b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.iolib.summary2 import summary_col\n",
    "info_dict={'R-squared' : lambda x: f\"{x.rsquared:.2f}\", \n",
    "           'No. observations' : lambda x: f\"{int(x.nobs):d}\"}\n",
    "\n",
    "\n",
    "results_table = summary_col(results=[results2,results3],\n",
    "                            float_format='%0.3f',\n",
    "                            stars = True,\n",
    "                            model_names=['Model 2',\n",
    "                                         'Model 3'],\n",
    "                            info_dict=info_dict,\n",
    "                            regressor_order=['Intercept',\n",
    "                                             'delivery_type_1[T.MeituanRun]',\n",
    "                                             'delivery_type_1[T.Merchant]',\n",
    "                                             'score',\n",
    "                                             'comment_number',\n",
    "                                             'avg_price_rmb',\n",
    "                                             'delivery_time_clean'])\n",
    "                            \n",
    "\n",
    "results_table.add_title('Table 4-2 - OLS Regressions Summaries for Model 1-5')\n",
    "\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613f5684",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE2=(np.square(results2.resid)).mean()  \n",
    "MSE3=(np.square(results3.resid)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43358cba",
   "metadata": {},
   "source": [
    "Analysis Assumptions:  \n",
    "1.Gauss markov assumption hold  \n",
    "2.Statistically significant  \n",
    "3.Hold all other indep variable constant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa43694c",
   "metadata": {},
   "source": [
    "EXAMPLE: Hold all other indepdent variable constant, every one-unit increase in score, y increases by about 43%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ebedc6",
   "metadata": {},
   "source": [
    "### 5-3 GLM Model  :   \n",
    "Log Link: Log(Y) – Models the logarithm of mean Y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681a781",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'month_sales_clean ~ score+comment_number+avg_price_rmb+delivery_time_clean+delivery_type_1+in_time_delivery_percent+min_price_rmb+shipping_fee_clean+Day_Time+Night_Time+Mid_Night_Time+recommend_Bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff092b3",
   "metadata": {},
   "source": [
    "#### 5-3-1 Poisson GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dd69d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = smf.glm(formula = formula, data=dffood, family=sm.families.Poisson(sm.families.links.log()))\n",
    "results4 = model4.fit()\n",
    "print(results4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf6c0da",
   "metadata": {},
   "source": [
    "WE have overdispersion (i.e. residual deviance is much larger than degrees of freedom), we want to use quasipoisson() instead of poisson()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b8649",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE4=np.square(results4.resid_response).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b3a70d",
   "metadata": {},
   "source": [
    "#### 5-3-2 Gaussian GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cae459",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = smf.glm(formula = formula, data=dffood, family=sm.families.Gaussian(sm.families.links.log()))\n",
    "results5 = model5.fit()\n",
    "print(results5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764654ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE5=np.square(results5.resid_response).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a2b883",
   "metadata": {},
   "source": [
    "### 5-4 Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853148fd",
   "metadata": {},
   "source": [
    "#### 5-4-1 MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed88e3c",
   "metadata": {},
   "source": [
    "Mean square error (MSE) is the average of the square of the errors. The larger the number the larger the error. Error in this case means the difference between the observed values y1, y2, y3, … and the predicted ones pred(y1), pred(y2), pred(y3), … We square each difference (pred(yn) – yn)) ^ 2 so that negative and positive values do not cancel each other out.  \n",
    "Simply put, the lower the value the better and 0 means the model is perfect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fea455",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE1) #level-level\n",
    "print(MSE2) #log-linear with Night_Time\n",
    "print(MSE3) #log-linear without Night_Time\n",
    "print(MSE4) #glm pois\n",
    "print(MSE5) #glm gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff73319",
   "metadata": {},
   "source": [
    "这里result 和r 不一样 idk why"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6526181",
   "metadata": {},
   "source": [
    "We find that log-linear with Night_Time model and log-linear without Night_Time model is better than other models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5066dede",
   "metadata": {},
   "source": [
    "#### 5-4-2 AIC and R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300713a3",
   "metadata": {},
   "source": [
    "The Akaike information criterion (AIC) is a mathematical method for evaluating how well a model fits the data it was generated from. In statistics, AIC is used to compare different possible models and determine which one is the best fit for the data.   \n",
    "AIC is calculated from:  \n",
    "the number of independent variables used to build the model   \n",
    "the maximum likelihood estimate of the model (how well the model reproduces the data)  \n",
    "  \n",
    "The best-fit model according to AIC is the one that explains the greatest amount of variation using the fewest possible independent variables.\n",
    "\n",
    "Lower AIC values indicate a better-fit model, and a model with a delta-AIC (the difference between the two AIC values being compared) of more than -2 is considered significantly better than the model it is being compared to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fd805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results2.aic)\n",
    "print(results3.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8e2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results2.rsquared)\n",
    "print(results3.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac5ced4",
   "metadata": {},
   "source": [
    "### Scatter fit plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1d4609",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scatter fit plot\n",
    "Yhat= results2.fittedvalues\n",
    "Y=dffood.month_sales_clean_log\n",
    "plt.scatter(Yhat,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb3dde7",
   "metadata": {},
   "source": [
    "Based on MSE result, R^2 and scatter plt, model 2 is the best.\n",
    "$$\n",
    "{log(MonthlySales)}_i = \\beta_0 + \\beta_1 {DeliveryType[T.MeituanRun]}_i + \\beta_2 {DeliveryType_1[T.Merchant]}_i+ \\beta_3 {Score}_i+ \\beta_4 {CommentNumber}_i+\\beta_5 {AvgPrice}_i+\\beta_6 {DeliveryTime}_i+\\beta_7 {InTimeDeliveryPercent}_i+\\beta_8 {MinPrice}_i+\\beta_9 {ShippingFee}_i+\\beta_{10} {DayTime}_i+\\beta_{11} {NightTime}_i+\\beta_{12} {MidNightTime}_i+\\beta_{13} {Recommendation}+u_i\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b0e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b292f1da",
   "metadata": {},
   "source": [
    "### 5-2 LASSO--Full Model(Baseline)(Include all features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7f4739",
   "metadata": {},
   "source": [
    "```\n",
    "lasso regression’s advantage over least squares linear regression is rooted in the bias-variance trade-off. As α increases, the flexibility of the lasso regression fit decreases, leading to decreased variance but increased bias. This procedure is more restrictive in estimating the coefficients and - depending on your value of α may set a number of them to exactly zero. This means in the final model the response variable will only be related to a small subset of the predictors—namely, those with nonzero coeffcient estimates. Therefore, selecting a good value of α is critical.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427e232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X (independent variable)\n",
    "# We will exclude the geo info data, such as province, city, district, lat & lng\n",
    "# We will exclude the month_sales_clean & log. Since this is output variable\n",
    "# For delivery_type, use Merchant as base\n",
    "# For category type, use DrugsDelivered as base since it only very few data                       \n",
    "X = dfclean.drop(['province',\n",
    "                  'city',\n",
    "                  'district',\n",
    "                  'name',\n",
    "                  'month_sales_clean',\n",
    "                  'category1',\n",
    "                  'delivery_type_1',\n",
    "                  'lat',\n",
    "                  'lng',\n",
    "                  'trade_area',\n",
    "                  'Merchant',\n",
    "                  'delivery_type_bin',\n",
    "                  'month_sales_clean_log',\n",
    "                  'DrugsDeliveried'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611bb92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Y (output variable)\n",
    "# Use month_sales_clean_log as target variable\n",
    "y = dfclean['month_sales_clean_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fda4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is all the numerical features \n",
    "numeric_features = ['score',\n",
    "                    'comment_number',\n",
    "                    'avg_price_rmb',\n",
    "                    'delivery_time_clean',\n",
    "                    'in_time_delivery_percent',\n",
    "                    'min_price_rmb',\n",
    "                    'shipping_fee_clean',\n",
    "                    'district population in (10 thousands)',\n",
    "                    'population density (people/square kilometer)',\n",
    "                    'Rent',\n",
    "                    'Female',\n",
    "                    'Male',\n",
    "                    '18 and below',\n",
    "                    '19-24',\n",
    "                    '25-34',\n",
    "                    '35-44',\n",
    "                    '45-54',\n",
    "                    '55 and above',\n",
    "                    '50 yuan and below',\n",
    "                    '50-100 yuan',\n",
    "                    '100-300 yuan',\n",
    "                    '300 yuan',\n",
    "                    'Shopping',\n",
    "                    'Catering Service',\n",
    "                    'Car Service',\n",
    "                    'Leisure',\n",
    "                    'Other',\n",
    "                    'Medicare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a646e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - test split 80% - 20% \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# Normalize the X_train data in X \n",
    "scaler = StandardScaler()\n",
    "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test[numeric_features] = scaler.fit_transform(X_test[numeric_features])\n",
    "\n",
    "# Define evaluation method\n",
    "cv = RepeatedKFold(n_splits=10,n_repeats = 3)\n",
    "\n",
    "# Define model\n",
    "model = LassoCV(cv=cv,n_jobs=-1)\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f11db4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract optimal alpha\n",
    "optimal_alpha = model.alpha_\n",
    "\n",
    "# Fit the lasso with optimal alpha \n",
    "lasso_best = Lasso(alpha=optimal_alpha)\n",
    "lasso_best.fit(X_train, y_train)\n",
    "\n",
    "print(f'Optimal Alpha: {optimal_alpha}')\n",
    "print('R squared training set', round(lasso_best.score(X_train, y_train)*100, 2))\n",
    "print('R squared test set', round(lasso_best.score(X_test, y_test)*100, 2))\n",
    "\n",
    "plt.semilogx(model.alphas_, model.mse_path_, \":\")\n",
    "plt.plot(\n",
    "    model.alphas_ ,\n",
    "    model.mse_path_.mean(axis=-1),\n",
    "    \"k\",\n",
    "    label=\"Average across the folds\",\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.axvline(\n",
    "    model.alpha_, linestyle=\"--\", color=\"k\", label=\"alpha: CV estimate\"\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"alphas\")\n",
    "plt.ylabel(\"Mean square error\")\n",
    "plt.title(\"Mean square error on each fold\")\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "ymin, ymax = 1, 1.5\n",
    "plt.ylim(ymin, ymax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81466ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficient from best lasso model\n",
    "for i,j in zip(lasso_best.coef_,X_train.columns):\n",
    "    print(round(i,2),\"       \",j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf35df76",
   "metadata": {},
   "source": [
    "## 5-3 P-Score Matching\n",
    "### Treatment = Merchant Vs NonMerchant \n",
    "### Subgroup= All Category1\n",
    "### Y = month_sale_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(dfclean,\n",
    "              values = ['month_sales_clean','comment_number','avg_price_rmb','in_time_delivery_percent','delivery_time_clean'],\n",
    "              index = 'delivery_type_bin',\n",
    "               aggfunc=np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea24fd2",
   "metadata": {},
   "source": [
    "#### 5-3-1: P-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d4682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X & Y for P-score prediction\n",
    "\n",
    "# Base on the LassoCV, we extract the feature that is non zero\n",
    "# Remind that we will include all the dummy variable of category1 feature regardless the lasso result\n",
    "Important_Feature = ['score',\n",
    "                     'comment_number',\n",
    "                     'avg_price_rmb',\n",
    "                    'delivery_time_clean',\n",
    "                    'in_time_delivery_percent',\n",
    "                     'min_price_rmb',\n",
    "                    'shipping_fee_clean',\n",
    "                    'Day_Time',\n",
    "                    'Night_Time',\n",
    "                    'Mid_Night_Time',\n",
    "                    'recommend_Bin',\n",
    "                     'district population in (10 thousands)',\n",
    "                     'population density (people/square kilometer)',\n",
    "                     'Rent',\n",
    "                     'Female',\n",
    "                     '18 and below',\n",
    "                     '19-24',\n",
    "                     '25-34',\n",
    "                     '35-44',\n",
    "                     '45-54',\n",
    "                     '55 and above',\n",
    "                     '50-100 yuan',\n",
    "                     '300 yuan',\n",
    "                     'Shopping',\n",
    "                     'Catering Service',\n",
    "                     'Car Service',\n",
    "                     'Leisure',\n",
    "                     'Other',\n",
    "                     'Medicare',\n",
    "                    'MeituanFlash',\n",
    "                    'MeituanRun',\n",
    "                     'DessertDrink',\n",
    "                     'DrugsDeliveried',\n",
    "                    'Foods',\n",
    "                     'FruitVegetables',\n",
    "                    'MarketConvenience',\n",
    "                     'RomanticFlowers',\n",
    "                    'SweetCake',]\n",
    "\n",
    "# For Y\n",
    "# The treatment we use is delivery_type_bin\n",
    "# 1 = Merchant 0 = Non-Merchant\n",
    "# Estimatae the Treatment Effect between Merchant and Meituan(Run+Flash) \n",
    "T = dfclean.delivery_type_bin\n",
    "\n",
    "\n",
    "# For X\n",
    "# 1: Regarding the input variable, we use important feature generated from above lasso regression where coefficient is non-zero\n",
    "# 2: Make sure it MUST NOT contain the treatment\n",
    "#    Therefore we drop 'MeituanRun' and 'MeituanFlash', cause we are predicting the delivery type as our P-Score(Which is same as Merchant)\n",
    "# 3: Since the Output of Matching analysis is the monthly sales data, we need to make sure that X MUST NOT contain 'month_sales_clean' and 'month_sales_clean_log' \n",
    "# 4: Remind that we will include all the dummy variable of category1 feature regardless the lasso result\n",
    "Important_Feature.remove('MeituanRun')\n",
    "Important_Feature.remove('MeituanFlash')\n",
    "X = dfclean[Important_Feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e7c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design pipline \n",
    "numeric_features= ['score',\n",
    "                    'comment_number',\n",
    "                    'avg_price_rmb',\n",
    "                    'delivery_time_clean',\n",
    "                    'in_time_delivery_percent',\n",
    "                    'min_price_rmb',\n",
    "                    'shipping_fee_clean',\n",
    "                    'district population in (10 thousands)',\n",
    "                    'population density (people/square kilometer)',\n",
    "                    'Rent',\n",
    "                    'Female',\n",
    "                    '18 and below',\n",
    "                    '19-24',\n",
    "                    '25-34',\n",
    "                    '35-44',\n",
    "                    '45-54',\n",
    "                    '55 and above',\n",
    "                    '50-100 yuan',\n",
    "                    '300 yuan',\n",
    "                    'Shopping',\n",
    "                    'Catering Service',\n",
    "                    'Car Service',\n",
    "                    'Leisure',\n",
    "                    'Other',\n",
    "                    'Medicare']\n",
    "\n",
    "\n",
    "numeric_transformer  = Pipeline(steps=[('Scaler',StandardScaler())])\n",
    "preprocessor         = ColumnTransformer(transformers=[('num',numeric_transformer,numeric_features)])\n",
    "clf                  = Pipeline(steps=[('preprocessor',preprocessor),(\"classifier\",lr())])\n",
    "grid                 = {\"classifier__C\": np.arange(1,10,0.1).tolist()}\n",
    "grid_search          = GridSearchCV(clf,grid,cv=10)\n",
    "grid_search.fit(X,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655a8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the optimal parameter in logist\n",
    "# Output the prediction base on the best parameter\n",
    "BestPip = Pipeline(steps=[('preprocessor',preprocessor),\n",
    "                          (\"classifier\",lr(C=grid_search.best_params_['classifier__C']))])\n",
    "BestPip.fit(X, T)\n",
    "predictions = BestPip.predict_proba(X)\n",
    "predictions_binary = BestPip.predict(X)\n",
    "\n",
    "# Eavluate the model\n",
    "print('Accuracy: {:.4f}\\n'.format(metrics.accuracy_score(T, predictions_binary)))\n",
    "print('Precision: {:.4f}\\n'.format(metrics.precision_score(T, predictions_binary)))\n",
    "print('Confusion matrix:\\n{}\\n'.format(metrics.confusion_matrix(T, predictions_binary)))\n",
    "print('F1 score is: {:.4f}'.format(metrics.f1_score(T, predictions_binary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce47141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(p):\n",
    "    logit_value = math.log(p / (1-p))\n",
    "    return logit_value\n",
    "sns.set(rc={'figure.figsize':(16,10)}, font_scale=1.3)\n",
    "\n",
    "predictions_logit = np.array([logit(xi) for xi in predictions[:,1]])\n",
    "# Density distribution of propensity score (logic) broken down by treatment status\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.suptitle('Density distribution plots for propensity score and logit(propensity score).')\n",
    "sns.kdeplot(x = predictions[:,1], hue = T , ax = ax[0])\n",
    "ax[0].set_title('Propensity Score')\n",
    "sns.kdeplot(x = predictions_logit, hue = T , ax = ax[1])\n",
    "ax[1].axvline(-0.85, ls='--')\n",
    "ax[0].axvline(0.3, ls='--')\n",
    "ax[1].set_title('Logit of Propensity Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a239f323",
   "metadata": {},
   "source": [
    "```\n",
    "The graph on the right (logit_propensity_score) demonstrates the density for each treatment status. There is overlap accross the range of values (-7,2.5). However on the left of \"-0.85\" there are a lot more 0's than 1's. On the right side of \"-0.85\", the opposite is true (a lot more 1's than 0's).\n",
    "\n",
    "This will affect later how we will perform the matching so we can have balanced groups. In practise, this means that for values X > -0.85, there are less untreated samples than treated. This will lead to untreated samples being used for more than one treated.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e743721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently this does not affect the results as all observations fall within this range.\n",
    "common_support = (predictions_logit > -10) & (predictions_logit < 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c88a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate a copy of X dataframe as out export CSV dataframe\n",
    "# Since we exclude month_sales_clean_log / MeituanRun / MeituanFlash/ Merchant in the X above \n",
    "# We gonna add them back to the export CSV dataframe\n",
    "PSMDF = X.copy()\n",
    "PSMDF.loc[:,'propensity_score'] = predictions[:,1]\n",
    "PSMDF.loc[:,'propensity_score_logit'] = predictions_logit\n",
    "PSMDF.loc[:,'month_sales_clean_log'] = dfclean.month_sales_clean_log\n",
    "PSMDF.loc[:,'month_sales_clean'] = dfclean.month_sales_clean\n",
    "PSMDF.loc[:,'MeituanFlash'] = dfclean.MeituanFlash\n",
    "PSMDF.loc[:,'MeituanRun'] = dfclean.MeituanRun\n",
    "PSMDF.loc[:,'Merchant'] = dfclean.Merchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c61c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the data\n",
    "# PSMDF.to_csv('Merchant_NonMerchant_CatergoryAll.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c11805d",
   "metadata": {},
   "source": [
    "## 5-4 P-Score Matching\n",
    "### Treatment = Merchant Vs MeituanFlash \n",
    "### Subgroup= Foods of  Category1\n",
    "### Y = month_sale_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163faca7",
   "metadata": {},
   "source": [
    "#### 5-4-1: P-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a37efd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X & Y for P-score prediction\n",
    "\n",
    "# Base on the LassoCV, we extract the feature that is non zero\n",
    "# Remind that we will include all the dummy variable of category1 feature regardless the lasso result\n",
    "Important_Feature = ['score',\n",
    "                     'comment_number',\n",
    "                     'avg_price_rmb',\n",
    "                    'delivery_time_clean',\n",
    "                    'in_time_delivery_percent',\n",
    "                     'min_price_rmb',\n",
    "                    'shipping_fee_clean',\n",
    "                    'Day_Time',\n",
    "                    'Night_Time',\n",
    "                    'Mid_Night_Time',\n",
    "                    'recommend_Bin',\n",
    "                     'district population in (10 thousands)',\n",
    "                     'population density (people/square kilometer)',\n",
    "                     'Rent',\n",
    "                     'Female',\n",
    "                     '18 and below',\n",
    "                     '19-24',\n",
    "                     '25-34',\n",
    "                     '35-44',\n",
    "                     '45-54',\n",
    "                     '55 and above',\n",
    "                     '50-100 yuan',\n",
    "                     '300 yuan',\n",
    "                     'Shopping',\n",
    "                     'Catering Service',\n",
    "                     'Car Service',\n",
    "                     'Leisure',\n",
    "                     'Other',\n",
    "                     'Medicare',\n",
    "                    'MeituanFlash',\n",
    "                    'MeituanRun',\n",
    "                     'DessertDrink',\n",
    "                     'DrugsDeliveried',\n",
    "                    'Foods',\n",
    "                     'FruitVegetables',\n",
    "                    'MarketConvenience',\n",
    "                     'RomanticFlowers',\n",
    "                    'SweetCake',]\n",
    "\n",
    "# For X\n",
    "# 1: Regarding the input variable, we use important feature generated from above lasso regression where coefficient is non-zero\n",
    "# 2: Make sure it MUST NOT contain the treatment\n",
    "#    Therefore we drop 'MeituanRun' and 'MeituanFlash', cause we are predicting the delivery type as our P-Score(Which is same as Merchant)\n",
    "# 3: Since the Output of Matching analysis is the monthly sales data, we need to make sure that X MUST NOT contain 'month_sales_clean' and 'month_sales_clean_log' \n",
    "# 4: Also, the subgroup is Foods, so we only incldue Foods + DessertDrink + SweetCake\n",
    "# 5: After filter out non-food category dummy variables, remove them from the X dataframe\n",
    "Important_Feature.remove('MeituanRun')\n",
    "Important_Feature.remove('MeituanFlash')\n",
    "X = dfclean[dfclean.MeituanRun==0][Important_Feature]\n",
    "X = X[X['MarketConvenience']!=1][X['FruitVegetables']!=1][X['RomanticFlowers']!=1][X['DrugsDeliveried']!=1]\n",
    "X.drop(['MarketConvenience','FruitVegetables','RomanticFlowers','DrugsDeliveried'],inplace=True,axis=1)\n",
    "\n",
    "\n",
    "# For T\n",
    "# The treatment we use is Merchant\n",
    "# 1 = Merchant 0 = Non-Merchant(Which is MeituanFlash,since we exclude MeituanRun)\n",
    "# Estimatae the Treatment Effect between Merchant and MeituanFlash (Exclude MeituanRun!!) \n",
    "T = dfclean[dfclean['MarketConvenience']!=1][dfclean['FruitVegetables']!=1][dfclean['RomanticFlowers']!=1][dfclean['DrugsDeliveried']!=1][dfclean['MeituanRun']!=1].Merchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ca03b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design pipline \n",
    "#numeric_features  = ['score', 'comment_number', 'avg_price_rmb', 'delivery_time_clean',\n",
    "#       'in_time_delivery_percent', 'min_price_rmb', 'shipping_fee_clean']\n",
    "numeric_features= ['score',\n",
    "                    'comment_number',\n",
    "                    'avg_price_rmb',\n",
    "                    'delivery_time_clean',\n",
    "                    'in_time_delivery_percent',\n",
    "                    'min_price_rmb',\n",
    "                    'shipping_fee_clean',\n",
    "                    'district population in (10 thousands)',\n",
    "                    'population density (people/square kilometer)',\n",
    "                    'Rent',\n",
    "                    'Female',\n",
    "                    '18 and below',\n",
    "                    '19-24',\n",
    "                    '25-34',\n",
    "                    '35-44',\n",
    "                    '45-54',\n",
    "                    '55 and above',\n",
    "                    '50-100 yuan',\n",
    "                    '300 yuan',\n",
    "                    'Shopping',\n",
    "                    'Catering Service',\n",
    "                    'Car Service',\n",
    "                    'Leisure',\n",
    "                    'Other',\n",
    "                    'Medicare']\n",
    "\n",
    "\n",
    "numeric_transformer  = Pipeline(steps=[('Scaler',StandardScaler())])\n",
    "preprocessor         = ColumnTransformer(transformers=[('num',numeric_transformer,numeric_features)])\n",
    "clf                  = Pipeline(steps=[('preprocessor',preprocessor),(\"classifier\",lr())])\n",
    "grid                 = {\"classifier__C\": np.arange(1,10,0.1).tolist()}\n",
    "grid_search          = GridSearchCV(clf,grid,cv=10)\n",
    "grid_search.fit(X,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef63b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the optimal parameter in logist\n",
    "# Output the prediction base on the best parameter\n",
    "BestPip = Pipeline(steps=[('preprocessor',preprocessor),\n",
    "                          (\"classifier\",lr(C=grid_search.best_params_['classifier__C']))])\n",
    "BestPip.fit(X, T)\n",
    "predictions = BestPip.predict_proba(X)\n",
    "predictions_binary = BestPip.predict(X)\n",
    "\n",
    "# Eavluate the model\n",
    "print('Accuracy: {:.4f}\\n'.format(metrics.accuracy_score(T, predictions_binary)))\n",
    "print('Precision: {:.4f}\\n'.format(metrics.precision_score(T, predictions_binary)))\n",
    "print('Confusion matrix:\\n{}\\n'.format(metrics.confusion_matrix(T, predictions_binary)))\n",
    "print('F1 score is: {:.4f}'.format(metrics.f1_score(T, predictions_binary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aac652",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def logit(p):\n",
    "    logit_value = math.log(p / (1-p))\n",
    "    return logit_value\n",
    "sns.set(rc={'figure.figsize':(16,10)}, font_scale=1.3)\n",
    "\n",
    "predictions_logit = np.array([logit(xi) for xi in predictions[:,1]])\n",
    "# Density distribution of propensity score (logic) broken down by treatment status\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.suptitle('Density distribution plots for propensity score and logit(propensity score).')\n",
    "sns.kdeplot(x = predictions[:,1], hue = T , ax = ax[0])\n",
    "ax[0].set_title('Propensity Score')\n",
    "sns.kdeplot(x = predictions_logit, hue = T , ax = ax[1])\n",
    "ax[1].axvline(-0.5, ls='--')\n",
    "ax[0].axvline(0.367, ls='--')\n",
    "ax[1].set_title('Logit of Propensity Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198226ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate a copy of X dataframe as out export CSV dataframe\n",
    "# Since we exclude month_sales_clean_log / MeituanRun / MeituanFlash/ Merchant in the X above \n",
    "# We gonna add them back to the export CSV dataframe\n",
    "PSMDF = X.copy()\n",
    "PSMDF.loc[:,'propensity_score'] = predictions[:,1]\n",
    "PSMDF.loc[:,'propensity_score_logit'] = predictions_logit\n",
    "PSMDF.loc[:,'month_sales_clean_log'] = dfclean[dfclean['MarketConvenience']!=1][dfclean['FruitVegetables']!=1][dfclean['RomanticFlowers']!=1][dfclean['DrugsDeliveried']!=1][dfclean['MeituanRun']!=1].month_sales_clean_log\n",
    "PSMDF.loc[:,'month_sales_clean'] = dfclean[dfclean['MarketConvenience']!=1][dfclean['FruitVegetables']!=1][dfclean['RomanticFlowers']!=1][dfclean['DrugsDeliveried']!=1][dfclean['MeituanRun']!=1].month_sales_clean\n",
    "PSMDF.loc[:,'MeituanFlash'] = dfclean[dfclean['MarketConvenience']!=1][dfclean['FruitVegetables']!=1][dfclean['RomanticFlowers']!=1][dfclean['DrugsDeliveried']!=1][dfclean['MeituanRun']!=1].MeituanFlash\n",
    "PSMDF.loc[:,'MeituanRun'] = dfclean[dfclean['MarketConvenience']!=1][dfclean['FruitVegetables']!=1][dfclean['RomanticFlowers']!=1][dfclean['DrugsDeliveried']!=1][dfclean['MeituanRun']!=1].MeituanRun\n",
    "PSMDF.loc[:,'Merchant'] = dfclean[dfclean['MarketConvenience']!=1][dfclean['FruitVegetables']!=1][dfclean['RomanticFlowers']!=1][dfclean['DrugsDeliveried']!=1][dfclean['MeituanRun']!=1].Merchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a239af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the data\n",
    "# PSMDF.to_csv('Merch_Flash_CatergoryFood.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518fb9a4",
   "metadata": {},
   "source": [
    "## 5-5 P-Score Matching\n",
    "### Treatment = Merchant Vs MeituanFlash \n",
    "### Subgroup= Foods of  Category1\n",
    "### Y = avg_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe87726",
   "metadata": {},
   "source": [
    "#### 5-5-1: P-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad2ea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X & Y for P-score prediction\n",
    "\n",
    "# Base on the LassoCV, we extract the feature that is non zero\n",
    "# Remind that we will include all the dummy variable of category1 feature regardless the lasso result\n",
    "Important_Feature = ['score',\n",
    "                     'comment_number',\n",
    "                     'avg_price_rmb',\n",
    "                    'delivery_time_clean',\n",
    "                    'in_time_delivery_percent',\n",
    "                     'min_price_rmb',\n",
    "                    'shipping_fee_clean',\n",
    "                    'Day_Time',\n",
    "                    'Night_Time',\n",
    "                    'Mid_Night_Time',\n",
    "                    'recommend_Bin',\n",
    "                     'district population in (10 thousands)',\n",
    "                     'population density (people/square kilometer)',\n",
    "                     'Rent',\n",
    "                     'Female',\n",
    "                     '18 and below',\n",
    "                     '19-24',\n",
    "                     '25-34',\n",
    "                     '35-44',\n",
    "                     '45-54',\n",
    "                     '55 and above',\n",
    "                     '50-100 yuan',\n",
    "                     '300 yuan',\n",
    "                     'Shopping',\n",
    "                     'Catering Service',\n",
    "                     'Car Service',\n",
    "                     'Leisure',\n",
    "                     'Other',\n",
    "                     'Medicare',\n",
    "                    'MeituanFlash',\n",
    "                    'MeituanRun',\n",
    "                     'DessertDrink',\n",
    "                     'DrugsDeliveried',\n",
    "                    'Foods',\n",
    "                     'FruitVegetables',\n",
    "                    'MarketConvenience',\n",
    "                     'RomanticFlowers',\n",
    "                    'SweetCake',]\n",
    "# For X\n",
    "# 1: Regarding the input variable, we use important feature generated from above lasso regression where coefficient is non-zero\n",
    "# 2: Make sure it MUST NOT contain the treatment\n",
    "#    Therefore we drop 'MeituanRun' and 'MeituanFlash', cause we are predicting the delivery type as our P-Score(Which is same as Merchant)\n",
    "# 3: Since the Output of Matching analysis is the avg_price_rmb data, we need to make sure that X MUST NOT contain 'avg_price_rmb'\n",
    "# 4: And also, different from above, month_sales_clean is no longer the Y(output) variable, so we will add month_sales_clean back to the feature list\n",
    "# 5: Also, the subgroup is Foods, so we only incldue Foods + DessertDrink + SweetCake\n",
    "# 6: After filter out non-food category dummy variables, remove them from the X dataframe\n",
    "Important_Feature.remove('MeituanRun')\n",
    "Important_Feature.remove('MeituanFlash')\n",
    "Important_Feature.remove('avg_price_rmb')\n",
    "Important_Feature.append('month_sales_clean')\n",
    "X = dfclean[dfclean.MeituanRun==0][Important_Feature]\n",
    "X = X[X['MarketConvenience']!=1][X['FruitVegetables']!=1][X['RomanticFlowers']!=1][X['DrugsDeliveried']!=1]\n",
    "X.drop(['MarketConvenience','FruitVegetables','RomanticFlowers','DrugsDeliveried'],inplace=True,axis=1)\n",
    "\n",
    "\n",
    "# For T\n",
    "# The treatment we use is Merchant\n",
    "# 1 = Merchant 0 = Non-Merchant(Which is MeituanFlash,since we exclude MeituanRun )\n",
    "# Estimatae the Treatment Effect between Merchant and Non-Merchant (Exclude MeituanRun!!) \n",
    "T = dfclean[dfclean['MarketConvenience']!=1][dfclean['FruitVegetables']!=1][dfclean['RomanticFlowers']!=1][dfclean['DrugsDeliveried']!=1][dfclean['MeituanRun']!=1].Merchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2a0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design pipline \n",
    "# Replaced avg_price wtih month_sales_clean \n",
    "# numeric_features  = ['score', 'comment_number', 'month_sales_clean', 'delivery_time_clean',\n",
    "#       'in_time_delivery_percent', 'min_price_rmb', 'shipping_fee_clean']\n",
    "\n",
    "numeric_features= ['score',\n",
    "                    'comment_number',\n",
    "                    'month_sales_clean',\n",
    "                    'delivery_time_clean',\n",
    "                    'in_time_delivery_percent',\n",
    "                    'min_price_rmb',\n",
    "                    'shipping_fee_clean',\n",
    "                    'district population in (10 thousands)',\n",
    "                    'population density (people/square kilometer)',\n",
    "                    'Rent',\n",
    "                    'Female',\n",
    "                    '18 and below',\n",
    "                    '19-24',\n",
    "                    '25-34',\n",
    "                    '35-44',\n",
    "                    '45-54',\n",
    "                    '55 and above',\n",
    "                    '50-100 yuan',\n",
    "                    '300 yuan',\n",
    "                    'Shopping',\n",
    "                    'Catering Service',\n",
    "                    'Car Service',\n",
    "                    'Leisure',\n",
    "                    'Other',\n",
    "                    'Medicare']\n",
    "\n",
    "\n",
    "numeric_transformer  = Pipeline(steps=[('Scaler',StandardScaler())])\n",
    "preprocessor         = ColumnTransformer(transformers=[('num',numeric_transformer,numeric_features)])\n",
    "clf                  = Pipeline(steps=[('preprocessor',preprocessor),(\"classifier\",lr())])\n",
    "grid                 = {\"classifier__C\": np.arange(1,10,0.1).tolist()}\n",
    "grid_search          = GridSearchCV(clf,grid,cv=10)\n",
    "grid_search.fit(X,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f089406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the optimal parameter in logist\n",
    "# Output the prediction base on the best parameter\n",
    "BestPip = Pipeline(steps=[('preprocessor',preprocessor),\n",
    "                          (\"classifier\",lr(C=grid_search.best_params_['classifier__C']))])\n",
    "BestPip.fit(X, T)\n",
    "predictions = BestPip.predict_proba(X)\n",
    "predictions_binary = BestPip.predict(X)\n",
    "\n",
    "# Eavluate the model\n",
    "print('Accuracy: {:.4f}\\n'.format(metrics.accuracy_score(T, predictions_binary)))\n",
    "print('Precision: {:.4f}\\n'.format(metrics.precision_score(T, predictions_binary)))\n",
    "print('Confusion matrix:\\n{}\\n'.format(metrics.confusion_matrix(T, predictions_binary)))\n",
    "print('F1 score is: {:.4f}'.format(metrics.f1_score(T, predictions_binary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88066e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(p):\n",
    "    logit_value = math.log(p / (1-p))\n",
    "    return logit_value\n",
    "sns.set(rc={'figure.figsize':(16,10)}, font_scale=1.3)\n",
    "\n",
    "predictions_logit = np.array([logit(xi) for xi in predictions[:,1]])\n",
    "# Density distribution of propensity score (logic) broken down by treatment status\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.suptitle('Density distribution plots for propensity score and logit(propensity score).')\n",
    "sns.kdeplot(x = predictions[:,1], hue = T , ax = ax[0])\n",
    "ax[0].set_title('Propensity Score')\n",
    "sns.kdeplot(x = predictions_logit, hue = T , ax = ax[1])\n",
    "ax[1].axvline(-0.5, ls='--')\n",
    "ax[0].axvline(0.367, ls='--')\n",
    "ax[1].set_title('Logit of Propensity Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db11a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate a copy of X dataframe as out export CSV dataframe\n",
    "# Since we exclude month_sales_clean_log / MeituanRun / MeituanFlash/ Merchant in the X above \n",
    "# We gonna add them back to the export CSV dataframe\n",
    "PSMDF = X.copy()\n",
    "PSMDF.loc[:,'propensity_score'] = predictions[:,1]\n",
    "PSMDF.loc[:,'propensity_score_logit'] = predictions_logit\n",
    "PSMDF.loc[:,'avg_price_rmb'] = dfclean[dfclean['MarketConvenience']!=1][dfclean['FruitVegetables']!=1][dfclean['RomanticFlowers']!=1][dfclean['DrugsDeliveried']!=1][dfclean['MeituanRun']!=1].avg_price_rmb\n",
    "PSMDF.loc[:,'MeituanFlash'] = dfclean[dfclean['MarketConvenience']!=1][dfclean['FruitVegetables']!=1][dfclean['RomanticFlowers']!=1][dfclean['DrugsDeliveried']!=1][dfclean['MeituanRun']!=1].MeituanFlash\n",
    "PSMDF.loc[:,'MeituanRun'] = dfclean[dfclean['MarketConvenience']!=1][dfclean['FruitVegetables']!=1][dfclean['RomanticFlowers']!=1][dfclean['DrugsDeliveried']!=1][dfclean['MeituanRun']!=1].MeituanRun\n",
    "PSMDF.loc[:,'Merchant'] = dfclean[dfclean['MarketConvenience']!=1][dfclean['FruitVegetables']!=1][dfclean['RomanticFlowers']!=1][dfclean['DrugsDeliveried']!=1][dfclean['MeituanRun']!=1].Merchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b91bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the data\n",
    "# PSMDF.to_csv('Merch_Flash_CatergoryFood(Y=AvgPrice).csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
